{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QuartzNEt_training_demo.ipynb","provenance":[{"file_id":"1CPvoFx6AREF85PI-otbrUR3KUTlR3HIa","timestamp":1629319057991}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Uva6C1Q8Fg9w","cellView":"form"},"source":["#@title Install Libraries for Quartznet\n","!pip install git+https://github.com/cehorn/GLRM.git \n","!pip3 install nemo-toolkit  # installs NeMo Core\n","!pip3 install nemo-asr # installs NeMo ASR collection\n","!pip3 install nemo-nlp # installs NeMo NLP collection\n","!pip3 install nemo-tts # installs NeMo TTS collection\n","!pip3 install kaldiio\n","!pip3 install pillow>=4.3.0\n","!pip3 install torch\n","!pip3 install ipython[all]\n","!pip3 install tqdm\n","!pip3 install sox\n","!pip3 install ruamel.yaml\n","!pip3 install jupyterlab\n","!pip3 install tqdm\n","!pip3 install boto3\n","!pip3 install requests\n","!pip3 install six\n","!pip3 install ipdb\n","!pip3 install h5py\n","!pip3 install html2text\n","!pip3 install nltk\n","!pip3 install progressbar\n","!pip3 install matplotlib\n","!pip3 install wget \n","!pip3 install tensorboardX\n","!pip3 install pandas\n","!pip3 install onnx\n","!pip3 install wget\n","!pip3 install num2words\n","!pip3 install librosa\n","!pip3 install inflect\n","!pip3 install kaldi-io\n","!pip3 install marshmallow\n","!pip3 install unidecode\n","!pip3 install sentencepiece\n","!pip3 install boto3\n","!pip3 install matplotlib\n","!pip3 install h5py\n","!pip3 install youtokentome\n","!pip3 install pydub\n","!pip3 install frozendict\n","!pip3 install pyannote.core\n","!pip3 install pyannote.metrics\n","!pip3 install g2p_en\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsnFeSAMvoP-"},"source":["# Importing the model"]},{"cell_type":"code","metadata":{"id":"yKiPE_VEGIkH"},"source":["import nemo.collections.asr as nemo_asr\n","model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"stt_de_quartznet15x5\")\n","\n","# use nemo_asr.models.ASRModel.restore_from() to load a model you trained yourself"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vU7iZmwctHsh","cellView":"form"},"source":["#@title Download playlist from Youtube\n","!git clone https://gitlab.com/Jaco-Assistant/corcua.git\n","!pip3 install -e corcua/\n","from corcua.corcua import downloaders\n","import os\n","link = (\n","            \"https://www.youtube.com/watch?v=erDUXM8mCS8&list=UUwRH985XgMYXQ6NxXDo8npw\"\n","        )\n","path = os.path.join(\"dataset\", \"kurzgesagt\") #set path for download\n","downloaders.youtube.Downloader().download_dataset(\n","            path=path, overwrite=True, args={\"link\": link, \"lang\": \"de\"}\n","        )\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTlC596v-3de","cellView":"form"},"source":["#@title Installing Dependencies for Data processing\n","!sudo apt-get install libasound2-plugins libasound2-python libsox-fmt-all\n","!sudo apt-get install -y sox\n","!sudo apt-get install sox libsox-fmt-mp3\n","!pip3 install num2words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19Gb1k5w_NLr","cellView":"form"},"source":["#@title Defining Processing Functions\n","\n","import json\n","import os\n","from typing import List\n","import re\n","import tqdm\n","import sox\n","from sox import Transformer\n","from pathlib import Path\n","from num2words import num2words\n","\n","# ==================================================================================================\n","\n","def process(x,output_wav_path): #transform the audio into mono, wav and 16000Hz\n","\n","    tfm = Transformer()\n","    tfm.rate(samplerate=16000)\n","    tfm.channels(n_channels=1)\n","    print(x,\"\\n\",output_wav_path)\n","    tfm.build(input_filepath=x, output_filepath=output_wav_path)\n","    duration = sox.file_info.duration(x)\n","    return duration\n","\n","def load_dataset(args): #loads the downloaded dataset and splits it and save it\n","    if \"path\" not in args:\n","        raise AttributeError(\"Some arguments are missing\")\n","\n","    print(\"\\nLoading transcripts ...\")\n","    align_path = os.path.join(args[\"path\"], \"alignment.json\")\n","    with open(align_path, \"r\", encoding=\"utf-8\") as file:\n","        aligns = json.load(file)\n","    chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\…\\{\\}\\【\\】\\・\\。\\『\\』\\、\\ー\\〜\\/\\-\\°\\–]'\n","    chars_to_ignore_regex = \"[^0-9a-zA-Z\\söÖüÜäÄß]+\"\n","    dataset = []\n","    dropped = 0\n","    for ii,a in enumerate(tqdm.tqdm(aligns)):\n","        file_path = a\n","        file_name = os.path.splitext(os.path.basename(file_path))[0]\n","        #audio_path = os.path.join(audio_clips_path, file_path)\n","        output_path = os.path.join(args[\"save_dir\"],\"wav\")\n","        output_wav_path = os.path.join(output_path, file_name + '.wav')\n","        os.makedirs(output_path, exist_ok=True)\n","        # Drop files including signs for notes\n","        try:\n","          duration = process(a,output_wav_path)\n","        except:\n","          continue\n","        drop = False\n","        for s in \"*([\":\n","            if aligns[a].startswith(s):\n","                drop = True\n","                break\n","        if drop:\n","            dropped += 1\n","            continue\n","        if duration<0.5: #drop files that are too short\n","          continue\n","        flag = False\n","        for ele in aligns[a]: #replace numbers with words (1 -> eins)\n","          \n","          if ele.isdigit():\n","              try:\n","                  K = num2words(ele, lang=\"de\")\n","                  aligns[a] = aligns[a].replace(ele, K)\n","              except:\n","                flag= True\n","        if flag == True:\n","          continue\n","        aligns[a] = re.sub(chars_to_ignore_regex, '', aligns[a]).lower() #remove special charecters\n","        if len(aligns[a])==0: #drop empty \n","          continue\n","        entry = {\n","            \"audio_filepath\": output_wav_path,\n","            \"duration\": duration,\n","            \"text\": aligns[a].strip(),\n","        }\n","        print(entry)\n","        dataset.append(entry)\n","\n","    train_i = int(0.9* (len(dataset)))\n","    test_i = int(0.05* (len(dataset)))\n","    val_i = len(dataset) - train_i - test_i\n","    \n","\n","    output_file= Path(os.path.join(args[\"save_dir\"], \"train_manifest.json\"))\n","    with output_file.open(mode='w+',encoding=\"utf-8\") as f:\n","        for d  in tqdm.tqdm(dataset[:train_i], total=train_i):\n","            wav_path, duration, text =d.values()\n","            f.write(\n","                json.dumps({'audio_filepath': os.path.abspath(wav_path), \"duration\": duration, 'text': text},ensure_ascii=False) + '\\n'\n","            )\n","    output_file= Path(os.path.join(args[\"save_dir\"], \"dev_manifest.json\"))\n","    with output_file.open(mode='w+',encoding=\"utf-8\") as f:\n","        for d in tqdm.tqdm(dataset[train_i:val_i+train_i], total=val_i):\n","            wav_path, duration, text =d.values()\n","            \n","            f.write(\n","                json.dumps({'audio_filepath': os.path.abspath(wav_path), \"duration\": duration, 'text': text},ensure_ascii=False) + '\\n'\n","            )\n","    output_file= Path(os.path.join(args[\"save_dir\"], \"test_manifest.json\"))\n","    with output_file.open(mode='w+',encoding=\"utf-8\") as f:\n","        for d in tqdm.tqdm(dataset[-test_i:], total=test_i):\n","            wav_path, duration, text =d.values()\n","            f.write(\n","                json.dumps({'audio_filepath': os.path.abspath(wav_path), \"duration\": duration, 'text': text},ensure_ascii=False) + '\\n'\n","            )\n","\n","    msg = \"Dropped {}/{} files with notes\"\n","    print(msg.format(dropped, len(aligns)))\n","\n","    return dataset\n","\n","def read_manifest(path): #for reading the dataset\n","    manifest = []\n","    with open(path, 'r',encoding=\"utf-8\") as f:\n","        for line in tqdm.tqdm(f, desc=\"Reading manifest data\"):\n","            line = line.replace(\"\\n\", \"\")\n","            data = json.loads(line)\n","            manifest.append(data)\n","    return manifest\n","from collections import defaultdict\n","\n","def get_charset(manifest_data): #for getting charecters appearing in files\n","    charset = defaultdict(int)\n","    for row in tqdm.tqdm(manifest_data, desc=\"Computing character set\"):\n","        text = row['text']\n","        for character in text:\n","            charset[character] += 1\n","    return charset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rZKEOHVzWL9"},"source":["#load_dataset({\"path\": \"path to downloaded dataset\",\"save_dir\":\"where to save the processed dataset\"})\n","ds=load_dataset({\"path\": \"dataset/kurzgesagt/\",\"save_dir\":\"datasets/kurzgesagt\"})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dw43buFmygcc"},"source":["Reading the dataset and checking the charecters"]},{"cell_type":"code","metadata":{"id":"W4tBsI3F5UF9"},"source":["train_manifest_data = read_manifest(\"datasets/kurzgesagt/train_manifest.json\")\n","\n","dev_manifest_data = read_manifest(\"datasets/kurzgesagt/dev_manifest.json\")\n","\n","test_manifest_data = read_manifest(\"datasets/kurzgesagt/test_manifest.json\")\n","\n","train_charset = get_charset(train_manifest_data)\n","dev_charset = get_charset(dev_manifest_data)\n","test_charset = get_charset(test_manifest_data)\n","\n","print(train_charset,\"\\n\",\n","dev_charset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AO4td8jymf_"},"source":["Set freeze_encoder to true if the dataset is relatively small (less than 700hrs)  otherwise set to false. This freezes the encoder but not the decoder "]},{"cell_type":"code","metadata":{"id":"149iWoC2gsRr"},"source":["import torch\n","import torch.nn as nn\n","\n","def enable_bn_se(m):\n","    if type(m) == nn.BatchNorm1d:\n","        m.train()\n","        for param in m.parameters():\n","            param.requires_grad_(True)\n","\n","    if 'SqueezeExcite' in type(m).__name__:\n","        m.train()\n","        for param in m.parameters():\n","            param.requires_grad_(True)\n","freeze_encoder = True      \n","if freeze_encoder:\n","  model.encoder.freeze()\n","  model.encoder.apply(enable_bn_se)\n","  #logging.info(\"Model encoder has been frozen, and batch normalization has been unfrozen\")\n","else:\n","  model.encoder.unfreeze()\n","  #logging.info(\"Model encoder has been un-frozen\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELRx5mkKy61e"},"source":["Settings for the models"]},{"cell_type":"code","metadata":{"id":"5TRdkNCJkZIr"},"source":["import copy\n","from omegaconf import OmegaConf, open_dict\n","\n","cfg = copy.deepcopy(model.cfg)\n","train_path =\"datasets/kurzgesagt/train_manifest.json\"\n","dev_path = \"datasets/kurzgesagt/dev_manifest.json\"\n","test_path = \"datasets/kurzgesagt/test_manifest.json\"\n","\n","with open_dict(cfg):    \n","  # Train dataset  (Concatenate train manifest cleaned and dev manifest cleaned)\n","  cfg.train_ds.manifest_filepath = f\"{train_path},{dev_path}\"\n","  #cfg.train_ds.labels = list(train_charset)\n","  cfg.train_ds.normalize_transcripts = False\n","  cfg.train_ds.batch_size = 32\n","  cfg.train_ds.num_workers = 8\n","  cfg.train_ds.pin_memory = True\n","  cfg.train_ds.trim_silence = True\n","\n","  # Validation dataset  (Use test dataset as validation, since we train using train + dev)\n","  cfg.validation_ds.manifest_filepath = test_path\n","  #cfg.validation_ds.labels = list(train_charset)\n","  cfg.validation_ds.normalize_transcripts = False\n","  cfg.validation_ds.batch_size = 8\n","  cfg.validation_ds.num_workers = 8\n","  cfg.validation_ds.pin_memory = True\n","  cfg.validation_ds.trim_silence = True\n","\n","model.setup_training_data(cfg.train_ds)\n","model.setup_multiple_validation_data(cfg.validation_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e6YiZrNPzBjk"},"source":["Settings for the optimizer"]},{"cell_type":"code","metadata":{"id":"FfpOGeKAo89v"},"source":["with open_dict(model.cfg.optim):\n","  model.cfg.optim.lr = 0.01\n","  model.cfg.optim.betas = [0.95, 0.5]  # from paper\n","  model.cfg.optim.weight_decay = 0.001  # Original weight decay\n","  model.cfg.optim.sched.warmup_steps = None  # Remove default number of steps of warmup\n","  model.cfg.optim.sched.warmup_ratio = 0.05  # 5 % warmup\n","  model.cfg.optim.sched.min_lr = 1e-5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wq3jVwCMzD00"},"source":["Settings for the Augmentaions (increase for small datasets) "]},{"cell_type":"code","metadata":{"id":"xpxNFGCxo-Gf"},"source":[" with open_dict(model.cfg.spec_augment):\n","   model.cfg.spec_augment.freq_masks = 2\n","   model.cfg.spec_augment.freq_width = 25\n","   model.cfg.spec_augment.time_masks = 2\n","   model.cfg.spec_augment.time_width = 0.05\n","\n","model.spec_augmentation = model.from_config_dict(model.cfg.spec_augment)\n","model._wer.use_cer = True\n","model._wer.log_prediction = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JNtWjSRlzMc5"},"source":["Settings for the trainer"]},{"cell_type":"code","metadata":{"id":"dw_sBtmdpUYC"},"source":["import torch\n","import pytorch_lightning as ptl\n","\n","if torch.cuda.is_available():\n","  gpus = 1\n","else:\n","  gpus = 0\n","\n","EPOCHS = 150  # No less than 100 epochs \n","\n","trainer = ptl.Trainer(gpus=gpus, \n","                      max_epochs=EPOCHS, \n","                      accumulate_grad_batches=1,\n","                      checkpoint_callback=False,\n","                      logger=False,\n","                      log_every_n_steps=5,\n","                      check_val_every_n_epoch=10)\n","\n","# Setup model with the trainer\n","model.set_trainer(trainer)\n","\n","# Finally, update the model's internal config\n","model.cfg = model._cfg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"naWLUm3T1hg0"},"source":["from nemo.utils import exp_manager\n","\n","# Environment variable generally used for multi-node multi-gpu training.\n","# In notebook environments, this flag is unnecessary and can cause logs of multiple training runs to overwrite each other.\n","os.environ.pop('NEMO_EXPM_VERSION', None)\n","\n","config = exp_manager.ExpManagerConfig(\n","    exp_dir=f'experiments/',\n","    name=f\"ASR-Model-Language\",\n","    checkpoint_callback_params=exp_manager.CallbackParams(\n","        monitor=\"val_wer\",\n","        mode=\"min\",\n","        always_save_nemo=True,\n","        save_best_model=True,\n","    ),\n",")\n","\n","config = OmegaConf.structured(config)\n","\n","logdir = exp_manager.exp_manager(trainer, config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0_5YP6I0MGT"},"source":["try:\n","  from google import colab\n","  COLAB_ENV = True\n","except (ImportError, ModuleNotFoundError):\n","  COLAB_ENV = False\n","\n","# Load the TensorBoard notebook extension\n","if COLAB_ENV:\n","  %load_ext tensorboard\n","  %tensorboard --logdir /content/experiments/\n","else:\n","  print(\"To use tensorboard, please use this notebook in a Google Colab environment.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s981U6ZrzSXN"},"source":["Train"]},{"cell_type":"code","metadata":{"id":"HFTl7mrnpfPU"},"source":["trainer.fit(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"euztNmBY0UfT"},"source":["save_path = f\"Model-de.nemo\"\n","model.save_to(f\"{save_path}\")\n","print(f\"Model saved at path : {os.getcwd() + os.path.sep + save_path}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mekPv9uuwapO"},"source":["#Inferencing a *file*"]},{"cell_type":"code","metadata":{"id":"TxLCl7fKQNU2"},"source":["!ffmpeg -loglevel panic -y -i INPUTFILE.wav -acodec pcm_s16le -ac 1 -ar 16000 OUTFILE.wav  # this transform the sound file to mono and 16000Hz \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kb84N7c8UIw"},"source":["model.transcribe(paths2audio_files=[\"OUTFILE.wav\"], batch_size=1, logprobs=False)"],"execution_count":null,"outputs":[]}]}